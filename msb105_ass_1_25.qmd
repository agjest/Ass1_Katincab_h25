---
title: "Is reproducibility good enough?"
author: "Ditt navn"
date: last-modified
csl: apa7.csl
bibliography: [reproducibility.bib, myrefs.bib]
format:
  html: default
  pdf: default
---


Reproducibility is increasingly recognized as a cornerstone of robust and reliable science.  
This paper explores the state of reproducibility across disciplines, including economics,  
and considers whether current practices are “good enough.” Drawing on lectures, literature,  
and examples of computable documents such as Quarto, the paper argues that although  
progress has been made, significant challenges remain in ensuring replicable research.


Scientific credibility depends on whether findings can be reproduced. The so-called  
“replication crisis” has revealed that many results, particularly in psychology, medicine,  
and social sciences, cannot be replicated [@ioannidis2005; @nosek2015].  
Reproducibility is not just about re-running an experiment—it is about transparency,  
data availability, and robust methodology [@simmons2011; @jasny2011].

Already in early economics, researchers such as Frisch emphasized the need for  
transparent models and methods [@frisch1933]. However, aspirations and practice have  
often diverged, raising the question: *Is reproducibility good enough today, or do we  
need stronger norms and better tools?*



The literature highlights multiple perspectives on reproducibility.  
Ioannidis [@ioannidis2005] famously argued that “most published research findings are false.”  
Others, like Nosek and colleagues [@nosek2015], have called for systemic reforms,  
including preregistration and open data. Jasny et al. [@jasny2011] highlighted the  
importance of replication studies in major journals, while Simmons et al. [@simmons2011]  
demonstrated how researcher degrees of freedom inflate false-positive rates.

In economics, early methodological contributions by Ezekiel [@ezekiel1933] and Frisch [@frisch1933]  
laid a foundation for statistical rigor. Yet audits of journal archives have shown  
serious gaps in reproducibility [@mccullough2008]. Despite explicit data archiving  
requirements, many published results cannot be replicated in practice.

New infrastructure is emerging. Bechhofer et al. [@bechhofer2013] describe  
**Research Objects** as digital packages that capture data, code, and context.  
Brase [@brase2009] explains how **DataCite DOIs** make datasets citable, linking  
publications directly to the underlying evidence. These developments extend  
beyond replication—they enable reuse and transparency.

Computable documents are another key innovation. Building on Knuth’s  
*literate programming* [@knuth1984], Gentleman and Temple Lang [@gentleman2007]  
introduced **Sweave** to combine R code and narrative. This idea expanded to  
**knitr** [@xie2015], R Markdown, and now **Quarto**, which integrates code,  
text, and references in one reproducible document.


Should replicability be the norm? Advocates argue that it is essential for  
trust, efficiency, and cumulative knowledge [@young2008]. Without replication,  
false results spread unchecked, wasting resources and damaging credibility.  
However, others point out that strict replication of every study is  
impractical. Some experiments are costly, context-specific, or require  
conditions that cannot be easily reproduced.

Quarto and similar tools address one part of the problem: transparency in analysis.  
By combining data, code, and text in one file, results become far easier to check  
and reproduce. Still, tools alone are insufficient. Cultural change is needed—  
journals must reward replication, and researchers must see transparency as part  
of good science rather than a burden.

Remaining challenges include selective reporting [@iyengar1988], lack of  
incentives, and the sheer complexity of modern data analysis. In economics,  
replication efforts show progress, but reproducibility is not yet standard practice.



Reproducibility is improving but not yet “good enough.” Progress is visible  
through data and code archives, DOIs, and computable documents. But incentives  
and cultural norms continue to lag behind technical solutions. The future of  
robust and reliable science depends on sustained effort to align tools, norms,  
and rewards in favor of reproducibility.



```{r}
sessionInfo()
